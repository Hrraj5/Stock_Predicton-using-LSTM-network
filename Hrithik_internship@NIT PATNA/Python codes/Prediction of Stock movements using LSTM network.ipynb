{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from keras.preprocessing.text import one_hot\n",
    "#from keras.preprocessing.text import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import History\n",
    "from numpy import zeros\n",
    "from keras.layers.embeddings import Embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prf1 import precision, recall, f1_score\n",
    "from keras.utils.vis_utils import plot_model\n",
    "#import pydot\n",
    "#import graphviz\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import LSTM\n",
    "import numpy\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from confusionMetrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from prf1 import precision, recall, f1_score\n",
    "from keras.utils import np_utils\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data extraction and labelling\n",
    "df=pd.read_excel('Tata_steel.xlsx')\n",
    "#print(df.info())\n",
    "df1=df['Field2']\n",
    "label =df['LABEL']\n",
    "tk=Tokenizer()\n",
    "tk.fit_on_texts(df1)\n",
    "index=tk.word_index\n",
    "#print(index)\n",
    "#x = tk.texts_to_sequences(df1)\n",
    "#seed = 7\n",
    "#numpy.random.seed(seed)\n",
    "##encoded_doc = tk.texts_to_matrix(df, mode='count')\n",
    "##print (encoded_doc)\n",
    "##max_length=15\n",
    "##padded_docs = sequence.pad_sequences(encoded_doc, maxlen=max_length, padding='pre')\n",
    "##print (padded_docs)\n",
    "vocab_size = len(index)\n",
    "encoded_docs=[one_hot(d,vocab_size) for d in df1] \n",
    "#print(encoded_docs)\n",
    "##############################Padding###############\n",
    "max_length=50\n",
    "padded_docs = sequence.pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "#print(padded_docs)\n",
    "#####################Encoded label######\n",
    "x_train1, x_val1, y_train1, y_val1=train_test_split(padded_docs,label, test_size=0.20,random_state=42)\n",
    "#print(x_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_val1.shape)\n",
    "#print(y_train1.shape)\n",
    "#print(y_val1.shape)\n",
    "sm = SMOTE(kind='regular')\n",
    "x_train,Y_train = sm.fit_sample(x_train1,y_train1)\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "x_val,y_val = sm.fit_sample(x_val1,y_val1)\n",
    "y_val = np_utils.to_categorical(y_val)\n",
    "\n",
    "#print('after smote',x_train.shape)\n",
    "#print(Y_train.shape)\n",
    "#print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors in Glove 6B 100d.\n",
      "Embedding Matrix\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt',encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    " \n",
    "print('Total %s word vectors in Glove 6B 100d.' % len(embeddings_index))\n",
    " \n",
    "# In[10]:\n",
    "embedding_matrix =zeros((vocab_size+ 1, 100))\n",
    "for word, i in tk.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector   \n",
    "print (\"Embedding Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 50, 100)           125600    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50, 200)           240800    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               120400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 487,204\n",
      "Trainable params: 361,604\n",
      "Non-trainable params: 125,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 480 samples, validate on 136 samples\n",
      "Epoch 1/75\n",
      " - 11s - loss: 1.3563 - acc: 0.2729 - precision: nan - recall: 0.0354 - f1_score: nan - val_loss: 1.5102 - val_acc: 0.1912 - val_precision: nan - val_recall: 0.0368 - val_f1_score: nan\n",
      "Epoch 2/75\n",
      " - 9s - loss: 1.3292 - acc: 0.3167 - precision: nan - recall: 0.0417 - f1_score: nan - val_loss: 1.5296 - val_acc: 0.2868 - val_precision: nan - val_recall: 0.0368 - val_f1_score: nan\n",
      "Epoch 3/75\n",
      " - 9s - loss: 1.3404 - acc: 0.3771 - precision: nan - recall: 0.0562 - f1_score: nan - val_loss: 1.5544 - val_acc: 0.3456 - val_precision: nan - val_recall: 0.0368 - val_f1_score: nan\n",
      "Epoch 4/75\n",
      " - 8s - loss: 1.3097 - acc: 0.3688 - precision: nan - recall: 0.0604 - f1_score: nan - val_loss: 1.4834 - val_acc: 0.3456 - val_precision: nan - val_recall: 0.0515 - val_f1_score: nan\n",
      "Epoch 5/75\n",
      " - 7s - loss: 1.2704 - acc: 0.4021 - precision: nan - recall: 0.0958 - f1_score: nan - val_loss: 1.3777 - val_acc: 0.3015 - val_precision: nan - val_recall: 0.0368 - val_f1_score: nan\n",
      "Epoch 6/75\n",
      " - 8s - loss: 1.2550 - acc: 0.3979 - precision: nan - recall: 0.0875 - f1_score: nan - val_loss: 1.4102 - val_acc: 0.4044 - val_precision: nan - val_recall: 0.0515 - val_f1_score: nan\n",
      "Epoch 7/75\n",
      " - 8s - loss: 1.1836 - acc: 0.4688 - precision: nan - recall: 0.1729 - f1_score: nan - val_loss: 1.3603 - val_acc: 0.3676 - val_precision: 0.3563 - val_recall: 0.0809 - val_f1_score: nan\n",
      "Epoch 8/75\n",
      " - 8s - loss: 1.1848 - acc: 0.4625 - precision: nan - recall: 0.1458 - f1_score: nan - val_loss: 1.3532 - val_acc: 0.3824 - val_precision: 0.5250 - val_recall: 0.2206 - val_f1_score: nan\n",
      "Epoch 9/75\n",
      " - 7s - loss: 1.1587 - acc: 0.4646 - precision: nan - recall: 0.1833 - f1_score: nan - val_loss: 1.4436 - val_acc: 0.3750 - val_precision: 0.3984 - val_recall: 0.3235 - val_f1_score: nan\n",
      "Epoch 10/75\n",
      " - 7s - loss: 1.0999 - acc: 0.4979 - precision: 0.6356 - recall: 0.2438 - f1_score: nan - val_loss: 1.4101 - val_acc: 0.3750 - val_precision: 0.4641 - val_recall: 0.1765 - val_f1_score: nan\n",
      "Epoch 11/75\n",
      " - 7s - loss: 1.0795 - acc: 0.5104 - precision: 0.7019 - recall: 0.2792 - f1_score: 0.3850 - val_loss: 1.3877 - val_acc: 0.3603 - val_precision: nan - val_recall: 0.0662 - val_f1_score: nan\n",
      "Epoch 12/75\n",
      " - 7s - loss: 1.0523 - acc: 0.5229 - precision: 0.7146 - recall: 0.2417 - f1_score: 0.3455 - val_loss: 1.4522 - val_acc: 0.3676 - val_precision: 0.4279 - val_recall: 0.2574 - val_f1_score: nan\n",
      "Epoch 13/75\n",
      " - 7s - loss: 1.0407 - acc: 0.5229 - precision: 0.6400 - recall: 0.2812 - f1_score: 0.3749 - val_loss: 1.4251 - val_acc: 0.3603 - val_precision: 0.6392 - val_recall: 0.1544 - val_f1_score: nan\n",
      "Epoch 14/75\n",
      " - 7s - loss: 0.9511 - acc: 0.5646 - precision: 0.7336 - recall: 0.2937 - f1_score: 0.3998 - val_loss: 1.5637 - val_acc: 0.3603 - val_precision: 0.4612 - val_recall: 0.2206 - val_f1_score: nan\n",
      "Epoch 15/75\n",
      " - 7s - loss: 0.9709 - acc: 0.5604 - precision: 0.7209 - recall: 0.2958 - f1_score: 0.4044 - val_loss: 1.5404 - val_acc: 0.3382 - val_precision: nan - val_recall: 0.1176 - val_f1_score: nan\n",
      "Epoch 16/75\n",
      " - 7s - loss: 0.9689 - acc: 0.5646 - precision: 0.7116 - recall: 0.2979 - f1_score: 0.4044 - val_loss: 1.4728 - val_acc: 0.3897 - val_precision: 0.3983 - val_recall: 0.3162 - val_f1_score: nan\n",
      "Epoch 17/75\n",
      " - 7s - loss: 0.8888 - acc: 0.5979 - precision: 0.7537 - recall: 0.4000 - f1_score: 0.4986 - val_loss: 1.4896 - val_acc: 0.3897 - val_precision: 0.4195 - val_recall: 0.3456 - val_f1_score: nan\n",
      "Epoch 18/75\n",
      " - 8s - loss: 0.8900 - acc: 0.6021 - precision: 0.7103 - recall: 0.4271 - f1_score: 0.5193 - val_loss: 2.0430 - val_acc: 0.3088 - val_precision: 0.3641 - val_recall: 0.2794 - val_f1_score: 0.3158\n",
      "Epoch 19/75\n",
      " - 7s - loss: 0.8896 - acc: 0.6083 - precision: 0.6890 - recall: 0.4479 - f1_score: 0.5316 - val_loss: 1.5341 - val_acc: 0.3971 - val_precision: 0.4487 - val_recall: 0.2794 - val_f1_score: nan\n",
      "Epoch 20/75\n",
      " - 8s - loss: 0.8359 - acc: 0.6104 - precision: 0.7043 - recall: 0.4938 - f1_score: 0.5697 - val_loss: 1.4172 - val_acc: 0.4044 - val_precision: 0.5233 - val_recall: 0.2941 - val_f1_score: 0.3741\n",
      "Epoch 21/75\n",
      " - 8s - loss: 0.7991 - acc: 0.6458 - precision: 0.7527 - recall: 0.5062 - f1_score: 0.5983 - val_loss: 1.7720 - val_acc: 0.3824 - val_precision: 0.3965 - val_recall: 0.3309 - val_f1_score: 0.3598\n",
      "Epoch 22/75\n",
      " - 9s - loss: 0.7629 - acc: 0.6896 - precision: 0.7369 - recall: 0.6292 - f1_score: 0.6745 - val_loss: 2.0443 - val_acc: 0.4044 - val_precision: 0.4069 - val_recall: 0.3529 - val_f1_score: 0.3770\n",
      "Epoch 23/75\n",
      " - 8s - loss: 0.6292 - acc: 0.7375 - precision: 0.7793 - recall: 0.6917 - f1_score: 0.7310 - val_loss: 1.8303 - val_acc: 0.4338 - val_precision: 0.4484 - val_recall: 0.4044 - val_f1_score: 0.4244\n",
      "Epoch 24/75\n",
      " - 8s - loss: 0.6810 - acc: 0.7375 - precision: 0.7767 - recall: 0.6958 - f1_score: 0.7324 - val_loss: 1.5668 - val_acc: 0.4265 - val_precision: 0.5017 - val_recall: 0.3529 - val_f1_score: 0.4102\n",
      "Epoch 25/75\n",
      " - 8s - loss: 0.6218 - acc: 0.7563 - precision: 0.7925 - recall: 0.7000 - f1_score: 0.7414 - val_loss: 2.0647 - val_acc: 0.3824 - val_precision: 0.4059 - val_recall: 0.3603 - val_f1_score: 0.3815\n",
      "Epoch 26/75\n",
      " - 9s - loss: 0.6140 - acc: 0.7833 - precision: 0.8082 - recall: 0.7458 - f1_score: 0.7740 - val_loss: 1.7223 - val_acc: 0.3676 - val_precision: 0.3817 - val_recall: 0.3382 - val_f1_score: 0.3578\n",
      "Epoch 27/75\n",
      " - 8s - loss: 0.5950 - acc: 0.7854 - precision: 0.8136 - recall: 0.7542 - f1_score: 0.7815 - val_loss: 1.8480 - val_acc: 0.4265 - val_precision: 0.4408 - val_recall: 0.3897 - val_f1_score: 0.4122\n",
      "Epoch 28/75\n",
      " - 9s - loss: 0.5686 - acc: 0.7958 - precision: 0.8086 - recall: 0.7812 - f1_score: 0.7941 - val_loss: 1.8167 - val_acc: 0.3603 - val_precision: 0.3642 - val_recall: 0.3456 - val_f1_score: 0.3542\n",
      "Epoch 29/75\n",
      " - 9s - loss: 0.5053 - acc: 0.8188 - precision: 0.8338 - recall: 0.8083 - f1_score: 0.8205 - val_loss: 1.9034 - val_acc: 0.3824 - val_precision: 0.3946 - val_recall: 0.3750 - val_f1_score: 0.3842\n",
      "Epoch 30/75\n",
      " - 8s - loss: 0.5289 - acc: 0.7937 - precision: 0.8067 - recall: 0.7833 - f1_score: 0.7941 - val_loss: 2.0233 - val_acc: 0.4044 - val_precision: 0.4216 - val_recall: 0.3971 - val_f1_score: 0.4089\n",
      "Epoch 31/75\n",
      " - 8s - loss: 0.4634 - acc: 0.8354 - precision: 0.8496 - recall: 0.8125 - f1_score: 0.8301 - val_loss: 1.9901 - val_acc: 0.4485 - val_precision: 0.4562 - val_recall: 0.4044 - val_f1_score: 0.4282\n",
      "Epoch 32/75\n",
      " - 9s - loss: 0.4293 - acc: 0.8354 - precision: 0.8464 - recall: 0.8271 - f1_score: 0.8364 - val_loss: 1.8936 - val_acc: 0.4191 - val_precision: 0.4334 - val_recall: 0.4044 - val_f1_score: 0.4179\n",
      "Epoch 33/75\n",
      " - 9s - loss: 0.4222 - acc: 0.8438 - precision: 0.8577 - recall: 0.8271 - f1_score: 0.8416 - val_loss: 2.0186 - val_acc: 0.4706 - val_precision: 0.4730 - val_recall: 0.4485 - val_f1_score: 0.4604\n",
      "Epoch 34/75\n",
      " - 9s - loss: 0.3780 - acc: 0.8708 - precision: 0.8779 - recall: 0.8562 - f1_score: 0.8666 - val_loss: 1.8806 - val_acc: 0.4338 - val_precision: 0.4383 - val_recall: 0.3824 - val_f1_score: 0.4073\n",
      "Epoch 35/75\n",
      " - 9s - loss: 0.3561 - acc: 0.8896 - precision: 0.8952 - recall: 0.8729 - f1_score: 0.8837 - val_loss: 2.3236 - val_acc: 0.3676 - val_precision: 0.3805 - val_recall: 0.3676 - val_f1_score: 0.3737\n",
      "Epoch 36/75\n",
      " - 8s - loss: 0.4130 - acc: 0.8354 - precision: 0.8538 - recall: 0.8208 - f1_score: 0.8363 - val_loss: 1.8117 - val_acc: 0.4118 - val_precision: 0.4267 - val_recall: 0.3971 - val_f1_score: 0.4107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/75\n",
      " - 8s - loss: 0.3343 - acc: 0.8917 - precision: 0.8992 - recall: 0.8833 - f1_score: 0.8909 - val_loss: 2.4099 - val_acc: 0.4118 - val_precision: 0.4221 - val_recall: 0.4118 - val_f1_score: 0.4167\n",
      "Epoch 38/75\n",
      " - 7s - loss: 0.3269 - acc: 0.8896 - precision: 0.8975 - recall: 0.8771 - f1_score: 0.8869 - val_loss: 1.9203 - val_acc: 0.4338 - val_precision: 0.4503 - val_recall: 0.4191 - val_f1_score: 0.4337\n",
      "Epoch 39/75\n",
      " - 7s - loss: 0.3230 - acc: 0.8896 - precision: 0.8959 - recall: 0.8750 - f1_score: 0.8850 - val_loss: 1.7847 - val_acc: 0.4118 - val_precision: 0.4378 - val_recall: 0.3897 - val_f1_score: 0.4110\n",
      "Epoch 40/75\n",
      " - 9s - loss: 0.3070 - acc: 0.8979 - precision: 0.9057 - recall: 0.8875 - f1_score: 0.8963 - val_loss: 2.1147 - val_acc: 0.3676 - val_precision: 0.3723 - val_recall: 0.3382 - val_f1_score: 0.3540\n",
      "Epoch 41/75\n",
      " - 7s - loss: 0.2470 - acc: 0.9187 - precision: 0.9264 - recall: 0.9125 - f1_score: 0.9191 - val_loss: 2.6168 - val_acc: 0.4338 - val_precision: 0.4457 - val_recall: 0.4338 - val_f1_score: 0.4394\n",
      "Epoch 42/75\n",
      " - 7s - loss: 0.2676 - acc: 0.9187 - precision: 0.9256 - recall: 0.9167 - f1_score: 0.9210 - val_loss: 2.1956 - val_acc: 0.4412 - val_precision: 0.4525 - val_recall: 0.4338 - val_f1_score: 0.4420\n",
      "Epoch 43/75\n",
      " - 7s - loss: 0.2815 - acc: 0.9042 - precision: 0.9111 - recall: 0.9000 - f1_score: 0.9054 - val_loss: 2.4195 - val_acc: 0.4265 - val_precision: 0.4456 - val_recall: 0.4265 - val_f1_score: 0.4357\n",
      "Epoch 44/75\n",
      " - 8s - loss: 0.3233 - acc: 0.8958 - precision: 0.8971 - recall: 0.8917 - f1_score: 0.8943 - val_loss: 2.1842 - val_acc: 0.4412 - val_precision: 0.4383 - val_recall: 0.4191 - val_f1_score: 0.4281\n",
      "Epoch 45/75\n",
      " - 9s - loss: 0.2818 - acc: 0.9208 - precision: 0.9247 - recall: 0.9146 - f1_score: 0.9195 - val_loss: 2.1690 - val_acc: 0.4412 - val_precision: 0.4578 - val_recall: 0.4412 - val_f1_score: 0.4491\n",
      "Epoch 46/75\n",
      " - 8s - loss: 0.2410 - acc: 0.9271 - precision: 0.9310 - recall: 0.9167 - f1_score: 0.9234 - val_loss: 2.6978 - val_acc: 0.4412 - val_precision: 0.4412 - val_recall: 0.4338 - val_f1_score: 0.4374\n",
      "Epoch 47/75\n",
      " - 7s - loss: 0.3145 - acc: 0.8979 - precision: 0.9014 - recall: 0.8958 - f1_score: 0.8985 - val_loss: 2.4513 - val_acc: 0.4044 - val_precision: 0.4010 - val_recall: 0.3971 - val_f1_score: 0.3990\n",
      "Epoch 48/75\n",
      " - 6s - loss: 0.2181 - acc: 0.9333 - precision: 0.9354 - recall: 0.9271 - f1_score: 0.9311 - val_loss: 2.2555 - val_acc: 0.5000 - val_precision: 0.4815 - val_recall: 0.4706 - val_f1_score: 0.4756\n",
      "Epoch 49/75\n",
      " - 7s - loss: 0.2563 - acc: 0.9250 - precision: 0.9268 - recall: 0.9167 - f1_score: 0.9216 - val_loss: 2.5709 - val_acc: 0.3824 - val_precision: 0.3939 - val_recall: 0.3750 - val_f1_score: 0.3840\n",
      "Epoch 50/75\n",
      " - 7s - loss: 0.2589 - acc: 0.9208 - precision: 0.9238 - recall: 0.9104 - f1_score: 0.9169 - val_loss: 2.3684 - val_acc: 0.4265 - val_precision: 0.4399 - val_recall: 0.4265 - val_f1_score: 0.4329\n",
      "Epoch 51/75\n",
      " - 8s - loss: 0.2725 - acc: 0.9229 - precision: 0.9265 - recall: 0.9187 - f1_score: 0.9225 - val_loss: 2.6857 - val_acc: 0.4191 - val_precision: 0.4235 - val_recall: 0.4191 - val_f1_score: 0.4213\n",
      "Epoch 52/75\n",
      " - 7s - loss: 0.2185 - acc: 0.9292 - precision: 0.9310 - recall: 0.9271 - f1_score: 0.9290 - val_loss: 2.4177 - val_acc: 0.4412 - val_precision: 0.4473 - val_recall: 0.4338 - val_f1_score: 0.4403\n",
      "Epoch 53/75\n",
      " - 7s - loss: 0.1775 - acc: 0.9458 - precision: 0.9478 - recall: 0.9458 - f1_score: 0.9468 - val_loss: 2.6076 - val_acc: 0.4265 - val_precision: 0.4319 - val_recall: 0.4265 - val_f1_score: 0.4291\n",
      "Epoch 54/75\n",
      " - 8s - loss: 0.1939 - acc: 0.9333 - precision: 0.9349 - recall: 0.9312 - f1_score: 0.9330 - val_loss: 2.4315 - val_acc: 0.4338 - val_precision: 0.4331 - val_recall: 0.4265 - val_f1_score: 0.4296\n",
      "Epoch 55/75\n",
      " - 7s - loss: 0.1896 - acc: 0.9458 - precision: 0.9494 - recall: 0.9438 - f1_score: 0.9464 - val_loss: 2.6992 - val_acc: 0.4338 - val_precision: 0.4301 - val_recall: 0.4265 - val_f1_score: 0.4282\n",
      "Epoch 56/75\n",
      " - 6s - loss: 0.2485 - acc: 0.9187 - precision: 0.9183 - recall: 0.9146 - f1_score: 0.9164 - val_loss: 1.8693 - val_acc: 0.5294 - val_precision: 0.5490 - val_recall: 0.5147 - val_f1_score: 0.5308\n",
      "Epoch 57/75\n",
      " - 8s - loss: 0.1777 - acc: 0.9417 - precision: 0.9511 - recall: 0.9354 - f1_score: 0.9429 - val_loss: 2.2277 - val_acc: 0.4412 - val_precision: 0.4392 - val_recall: 0.4338 - val_f1_score: 0.4364\n",
      "Epoch 58/75\n",
      " - 8s - loss: 0.1090 - acc: 0.9708 - precision: 0.9708 - recall: 0.9708 - f1_score: 0.9708 - val_loss: 2.7449 - val_acc: 0.4706 - val_precision: 0.4735 - val_recall: 0.4706 - val_f1_score: 0.4720\n",
      "Epoch 59/75\n",
      " - 9s - loss: 0.1395 - acc: 0.9563 - precision: 0.9583 - recall: 0.9563 - f1_score: 0.9573 - val_loss: 2.6767 - val_acc: 0.4338 - val_precision: 0.4368 - val_recall: 0.4338 - val_f1_score: 0.4352\n",
      "Epoch 60/75\n",
      " - 9s - loss: 0.1220 - acc: 0.9604 - precision: 0.9604 - recall: 0.9604 - f1_score: 0.9604 - val_loss: 2.6208 - val_acc: 0.4559 - val_precision: 0.4603 - val_recall: 0.4559 - val_f1_score: 0.4580\n",
      "Epoch 61/75\n",
      " - 9s - loss: 0.2142 - acc: 0.9438 - precision: 0.9476 - recall: 0.9438 - f1_score: 0.9456 - val_loss: 2.3439 - val_acc: 0.4926 - val_precision: 0.4910 - val_recall: 0.4853 - val_f1_score: 0.4880\n",
      "Epoch 62/75\n",
      " - 9s - loss: 0.1881 - acc: 0.9458 - precision: 0.9449 - recall: 0.9417 - f1_score: 0.9432 - val_loss: 2.6106 - val_acc: 0.4559 - val_precision: 0.4496 - val_recall: 0.4412 - val_f1_score: 0.4451\n",
      "Epoch 63/75\n",
      " - 9s - loss: 0.1590 - acc: 0.9542 - precision: 0.9599 - recall: 0.9542 - f1_score: 0.9569 - val_loss: 2.7053 - val_acc: 0.4632 - val_precision: 0.4637 - val_recall: 0.4485 - val_f1_score: 0.4559\n",
      "Epoch 64/75\n",
      " - 9s - loss: 0.1551 - acc: 0.9667 - precision: 0.9667 - recall: 0.9667 - f1_score: 0.9667 - val_loss: 2.5155 - val_acc: 0.4485 - val_precision: 0.4466 - val_recall: 0.4338 - val_f1_score: 0.4399\n",
      "Epoch 65/75\n",
      " - 8s - loss: 0.1023 - acc: 0.9771 - precision: 0.9811 - recall: 0.9750 - f1_score: 0.9779 - val_loss: 2.6022 - val_acc: 0.4632 - val_precision: 0.4632 - val_recall: 0.4632 - val_f1_score: 0.4632\n",
      "Epoch 66/75\n",
      " - 8s - loss: 0.1232 - acc: 0.9688 - precision: 0.9688 - recall: 0.9667 - f1_score: 0.9677 - val_loss: 2.9321 - val_acc: 0.4706 - val_precision: 0.4701 - val_recall: 0.4632 - val_f1_score: 0.4666\n",
      "Epoch 67/75\n",
      " - 9s - loss: 0.1034 - acc: 0.9750 - precision: 0.9769 - recall: 0.9750 - f1_score: 0.9759 - val_loss: 2.7049 - val_acc: 0.4926 - val_precision: 0.4961 - val_recall: 0.4853 - val_f1_score: 0.4904\n",
      "Epoch 68/75\n",
      " - 7s - loss: 0.1511 - acc: 0.9625 - precision: 0.9625 - recall: 0.9604 - f1_score: 0.9614 - val_loss: 2.5535 - val_acc: 0.4779 - val_precision: 0.4806 - val_recall: 0.4632 - val_f1_score: 0.4716\n",
      "Epoch 69/75\n",
      " - 8s - loss: 0.1193 - acc: 0.9667 - precision: 0.9707 - recall: 0.9667 - f1_score: 0.9686 - val_loss: 2.7492 - val_acc: 0.4632 - val_precision: 0.4678 - val_recall: 0.4632 - val_f1_score: 0.4654\n",
      "Epoch 70/75\n",
      " - 8s - loss: 0.1409 - acc: 0.9563 - precision: 0.9563 - recall: 0.9563 - f1_score: 0.9563 - val_loss: 2.7001 - val_acc: 0.4118 - val_precision: 0.4118 - val_recall: 0.4118 - val_f1_score: 0.4118\n",
      "Epoch 71/75\n",
      " - 9s - loss: 0.0889 - acc: 0.9750 - precision: 0.9786 - recall: 0.9729 - f1_score: 0.9757 - val_loss: 2.8078 - val_acc: 0.4853 - val_precision: 0.4868 - val_recall: 0.4853 - val_f1_score: 0.4860\n",
      "Epoch 72/75\n",
      " - 8s - loss: 0.0877 - acc: 0.9729 - precision: 0.9787 - recall: 0.9688 - f1_score: 0.9735 - val_loss: 2.5541 - val_acc: 0.4706 - val_precision: 0.4665 - val_recall: 0.4559 - val_f1_score: 0.4609\n",
      "Epoch 73/75\n",
      " - 8s - loss: 0.0800 - acc: 0.9750 - precision: 0.9750 - recall: 0.9750 - f1_score: 0.9750 - val_loss: 2.7895 - val_acc: 0.4632 - val_precision: 0.4583 - val_recall: 0.4559 - val_f1_score: 0.4571\n",
      "Epoch 74/75\n",
      " - 7s - loss: 0.0964 - acc: 0.9750 - precision: 0.9750 - recall: 0.9750 - f1_score: 0.9750 - val_loss: 2.4184 - val_acc: 0.5000 - val_precision: 0.5024 - val_recall: 0.4853 - val_f1_score: 0.4935\n",
      "Epoch 75/75\n",
      " - 8s - loss: 0.0687 - acc: 0.9854 - precision: 0.9854 - recall: 0.9854 - f1_score: 0.9854 - val_loss: 2.9004 - val_acc: 0.5074 - val_precision: 0.5054 - val_recall: 0.5000 - val_f1_score: 0.5026\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.50      0.45        34\n",
      "          1       0.81      0.62      0.70        34\n",
      "          2       0.43      0.74      0.54        34\n",
      "          3       0.55      0.18      0.27        34\n",
      "\n",
      "avg / total       0.55      0.51      0.49       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    " \n",
    " \n",
    "#############embedding layers#########################\n",
    " \n",
    "history=History()\n",
    "predictions_train=[]\n",
    "predictions_test=[]\n",
    "filter_sizes = [3,4,5]\n",
    "fold_training=numpy.zeros(shape=50)\n",
    "fold_test=numpy.zeros(shape=50)\n",
    "##embedding_vecor_length =32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1, 100,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False))\n",
    "##model.add(Embedding(vocab_size,8, input_length=embedding_vecor_length))\n",
    "#kfold = KFold(n_splits=20, shuffle=True, random_state=7)\n",
    "#cvscores = []\n",
    "#ith=1\n",
    "#for train,test in kfold.split(padded_docs,labels):\n",
    "    #print('Fold=',ith)\n",
    "    #ith=ith+1\n",
    "    #print(train,test)\n",
    "    #X_train, X_test = padded_docs[train], padded_docs[test]\n",
    "    #Y_train, Y_test = labels[train], labels[test]\n",
    "model.add(LSTM(200,return_sequences=True))\n",
    "#model.add(LSTM(100,return_sequences=True))\n",
    "#model.add(LSTM(200,return_sequences=True))\n",
    "#model.add(LSTM(200,return_sequences=True,recurrent_dropout=0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='RMSprop',\n",
    "              metrics=['acc', precision, recall, f1_score])\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', precision,recall,f1_score])\n",
    "print(model.summary())\n",
    "history=model.fit(x_train, Y_train,validation_data=(x_val,y_val),epochs=75, batch_size=16,verbose=2, callbacks=[history])\n",
    "predictions = model.predict(x_val)\n",
    "b=np.zeros_like(predictions)\n",
    "b[np.arange(len(predictions)), predictions.argmax(1)]=1\n",
    "print( metrics.classification_report(y_val,b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
