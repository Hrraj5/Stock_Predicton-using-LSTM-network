{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors in Glove 6B 100d.\n",
      "Embedding Matrix\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 50, 100)           211100    \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 50, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 50, 200)           240800    \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 50, 200)           320800    \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 50, 200)           320800    \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 100)               120400    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 1,294,704\n",
      "Trainable params: 1,083,604\n",
      "Non-trainable params: 211,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 398 samples, validate on 21 samples\n",
      "Epoch 1/75\n",
      " - 28s - loss: 1.1534 - acc: 0.5050 - precision: nan - recall: 0.3090 - f1_score: nan - val_loss: 1.0009 - val_acc: 0.5714 - val_precision: 0.5518 - val_recall: 0.4762 - val_f1_score: 0.5109\n",
      "Epoch 2/75\n",
      " - 19s - loss: 1.0813 - acc: 0.5553 - precision: nan - recall: 0.4121 - f1_score: nan - val_loss: 0.9773 - val_acc: 0.5714 - val_precision: 0.8413 - val_recall: 0.2857 - val_f1_score: 0.4139\n",
      "Epoch 3/75\n",
      " - 21s - loss: 1.0712 - acc: 0.5452 - precision: 0.6757 - recall: 0.3618 - f1_score: 0.4295 - val_loss: 0.9656 - val_acc: 0.5714 - val_precision: 0.5767 - val_recall: 0.5238 - val_f1_score: 0.5489\n",
      "Epoch 4/75\n",
      " - 20s - loss: 1.0909 - acc: 0.5578 - precision: 0.6216 - recall: 0.4548 - f1_score: 0.5120 - val_loss: 0.9958 - val_acc: 0.5714 - val_precision: 0.5767 - val_recall: 0.5238 - val_f1_score: 0.5489\n",
      "Epoch 5/75\n",
      " - 19s - loss: 1.0007 - acc: 0.5779 - precision: 0.6565 - recall: 0.4849 - f1_score: 0.5475 - val_loss: 1.0063 - val_acc: 0.5714 - val_precision: 0.5990 - val_recall: 0.5714 - val_f1_score: 0.5849\n",
      "Epoch 6/75\n",
      " - 19s - loss: 0.9569 - acc: 0.5980 - precision: 0.6432 - recall: 0.5276 - f1_score: 0.5770 - val_loss: 0.9378 - val_acc: 0.5714 - val_precision: 0.6537 - val_recall: 0.3810 - val_f1_score: 0.4777\n",
      "Epoch 7/75\n",
      " - 18s - loss: 0.9486 - acc: 0.6080 - precision: 0.6448 - recall: 0.5151 - f1_score: 0.5597 - val_loss: 0.9717 - val_acc: 0.5714 - val_precision: 0.5833 - val_recall: 0.4762 - val_f1_score: 0.5238\n",
      "Epoch 8/75\n",
      " - 18s - loss: 0.9255 - acc: 0.6256 - precision: 0.6802 - recall: 0.5126 - f1_score: 0.5709 - val_loss: 1.0401 - val_acc: 0.5238 - val_precision: 0.6537 - val_recall: 0.3810 - val_f1_score: 0.4777\n",
      "Epoch 9/75\n",
      " - 18s - loss: 0.9085 - acc: 0.6055 - precision: 0.6862 - recall: 0.5101 - f1_score: 0.5631 - val_loss: 1.0509 - val_acc: 0.5714 - val_precision: 0.7143 - val_recall: 0.3810 - val_f1_score: 0.4921\n",
      "Epoch 10/75\n",
      " - 21s - loss: 0.8654 - acc: 0.6281 - precision: 0.6685 - recall: 0.5276 - f1_score: 0.5789 - val_loss: 0.9727 - val_acc: 0.5714 - val_precision: 0.5518 - val_recall: 0.4762 - val_f1_score: 0.5109\n",
      "Epoch 11/75\n",
      " - 19s - loss: 0.9308 - acc: 0.6055 - precision: 0.7112 - recall: 0.4824 - f1_score: 0.5443 - val_loss: 1.0696 - val_acc: 0.4762 - val_precision: 0.5238 - val_recall: 0.4762 - val_f1_score: 0.4987\n",
      "Epoch 12/75\n",
      " - 19s - loss: 0.8558 - acc: 0.6256 - precision: 0.7244 - recall: 0.5176 - f1_score: 0.5893 - val_loss: 1.0209 - val_acc: 0.5714 - val_precision: 0.6032 - val_recall: 0.3810 - val_f1_score: 0.4643\n",
      "Epoch 13/75\n",
      " - 20s - loss: 0.8561 - acc: 0.6080 - precision: 0.6807 - recall: 0.4950 - f1_score: 0.5549 - val_loss: 1.0524 - val_acc: 0.4762 - val_precision: 0.5604 - val_recall: 0.3810 - val_f1_score: 0.4517\n",
      "Epoch 14/75\n",
      " - 19s - loss: 0.8410 - acc: 0.6759 - precision: 0.7426 - recall: 0.5176 - f1_score: 0.6009 - val_loss: 1.1225 - val_acc: 0.5238 - val_precision: 0.5238 - val_recall: 0.4762 - val_f1_score: 0.4987\n",
      "Epoch 15/75\n",
      " - 19s - loss: 0.8451 - acc: 0.6608 - precision: 0.7080 - recall: 0.5352 - f1_score: 0.6007 - val_loss: 1.0884 - val_acc: 0.6667 - val_precision: 0.6190 - val_recall: 0.4762 - val_f1_score: 0.5374\n",
      "Epoch 16/75\n",
      " - 18s - loss: 0.7926 - acc: 0.6960 - precision: 0.7195 - recall: 0.6658 - f1_score: 0.6905 - val_loss: 1.0807 - val_acc: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.6190\n",
      "Epoch 17/75\n",
      " - 19s - loss: 0.8115 - acc: 0.6859 - precision: 0.7162 - recall: 0.6508 - f1_score: 0.6813 - val_loss: 1.0717 - val_acc: 0.6190 - val_precision: 0.6825 - val_recall: 0.6190 - val_f1_score: 0.6491\n",
      "Epoch 18/75\n",
      " - 18s - loss: 0.7547 - acc: 0.7136 - precision: 0.7213 - recall: 0.6809 - f1_score: 0.7002 - val_loss: 1.0422 - val_acc: 0.6190 - val_precision: 0.6491 - val_recall: 0.6190 - val_f1_score: 0.6337\n",
      "Epoch 19/75\n",
      " - 19s - loss: 0.7754 - acc: 0.7186 - precision: 0.7320 - recall: 0.6834 - f1_score: 0.7059 - val_loss: 1.2956 - val_acc: 0.4762 - val_precision: 0.4486 - val_recall: 0.4286 - val_f1_score: 0.4383\n",
      "Epoch 20/75\n",
      " - 17s - loss: 0.7490 - acc: 0.7236 - precision: 0.7378 - recall: 0.7060 - f1_score: 0.7209 - val_loss: 1.2517 - val_acc: 0.4762 - val_precision: 0.4987 - val_recall: 0.4762 - val_f1_score: 0.4872\n",
      "Epoch 21/75\n",
      " - 15s - loss: 0.7546 - acc: 0.7261 - precision: 0.7481 - recall: 0.7186 - f1_score: 0.7326 - val_loss: 1.0910 - val_acc: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.6190\n",
      "Epoch 22/75\n",
      " - 16s - loss: 0.7102 - acc: 0.7161 - precision: 0.7226 - recall: 0.6709 - f1_score: 0.6948 - val_loss: 1.5215 - val_acc: 0.4762 - val_precision: 0.4709 - val_recall: 0.4286 - val_f1_score: 0.4486\n",
      "Epoch 23/75\n",
      " - 18s - loss: 0.7031 - acc: 0.7487 - precision: 0.7630 - recall: 0.7286 - f1_score: 0.7449 - val_loss: 1.1465 - val_acc: 0.5238 - val_precision: 0.5238 - val_recall: 0.4762 - val_f1_score: 0.4987\n",
      "Epoch 24/75\n",
      " - 20s - loss: 0.7382 - acc: 0.7312 - precision: 0.7600 - recall: 0.7010 - f1_score: 0.7279 - val_loss: 1.3078 - val_acc: 0.5238 - val_precision: 0.4709 - val_recall: 0.4286 - val_f1_score: 0.4486\n",
      "Epoch 25/75\n",
      " - 21s - loss: 0.6988 - acc: 0.7211 - precision: 0.7430 - recall: 0.6834 - f1_score: 0.7102 - val_loss: 1.2164 - val_acc: 0.5238 - val_precision: 0.4987 - val_recall: 0.4762 - val_f1_score: 0.4872\n",
      "Epoch 26/75\n",
      " - 20s - loss: 0.6770 - acc: 0.7613 - precision: 0.7736 - recall: 0.7312 - f1_score: 0.7511 - val_loss: 1.0397 - val_acc: 0.6190 - val_precision: 0.6429 - val_recall: 0.5238 - val_f1_score: 0.5767\n",
      "Epoch 27/75\n",
      " - 20s - loss: 0.6384 - acc: 0.7889 - precision: 0.7997 - recall: 0.7613 - f1_score: 0.7796 - val_loss: 1.2120 - val_acc: 0.6667 - val_precision: 0.6296 - val_recall: 0.5714 - val_f1_score: 0.5990\n",
      "Epoch 28/75\n",
      " - 18s - loss: 0.5616 - acc: 0.8116 - precision: 0.8154 - recall: 0.7915 - f1_score: 0.8030 - val_loss: 2.0272 - val_acc: 0.3333 - val_precision: 0.3197 - val_recall: 0.2381 - val_f1_score: 0.2717\n",
      "Epoch 29/75\n",
      " - 20s - loss: 0.6078 - acc: 0.7663 - precision: 0.7934 - recall: 0.7487 - f1_score: 0.7697 - val_loss: 1.2416 - val_acc: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.5714\n",
      "Epoch 30/75\n",
      " - 20s - loss: 0.6113 - acc: 0.7864 - precision: 0.8085 - recall: 0.7638 - f1_score: 0.7844 - val_loss: 1.3744 - val_acc: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.6190\n",
      "Epoch 31/75\n",
      " - 20s - loss: 0.5412 - acc: 0.8141 - precision: 0.8392 - recall: 0.7889 - f1_score: 0.8122 - val_loss: 1.2722 - val_acc: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.6190\n",
      "Epoch 32/75\n",
      " - 19s - loss: 0.5346 - acc: 0.8015 - precision: 0.8139 - recall: 0.7940 - f1_score: 0.8036 - val_loss: 1.2457 - val_acc: 0.5714 - val_precision: 0.5767 - val_recall: 0.5238 - val_f1_score: 0.5489\n",
      "Epoch 33/75\n",
      " - 18s - loss: 0.5075 - acc: 0.8291 - precision: 0.8354 - recall: 0.8166 - f1_score: 0.8256 - val_loss: 1.2472 - val_acc: 0.5238 - val_precision: 0.5489 - val_recall: 0.5238 - val_f1_score: 0.5360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/75\n",
      " - 18s - loss: 0.6189 - acc: 0.8141 - precision: 0.8277 - recall: 0.8040 - f1_score: 0.8152 - val_loss: 1.2357 - val_acc: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.6190\n",
      "Epoch 35/75\n",
      " - 21s - loss: 0.5076 - acc: 0.8518 - precision: 0.8561 - recall: 0.8392 - f1_score: 0.8474 - val_loss: 1.5270 - val_acc: 0.5238 - val_precision: 0.5238 - val_recall: 0.4762 - val_f1_score: 0.4987\n",
      "Epoch 36/75\n",
      " - 20s - loss: 0.5256 - acc: 0.8417 - precision: 0.8515 - recall: 0.8342 - f1_score: 0.8425 - val_loss: 1.2629 - val_acc: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.6190\n",
      "Epoch 37/75\n",
      " - 18s - loss: 0.4589 - acc: 0.8568 - precision: 0.8615 - recall: 0.8492 - f1_score: 0.8551 - val_loss: 1.9560 - val_acc: 0.4286 - val_precision: 0.4398 - val_recall: 0.3810 - val_f1_score: 0.4080\n",
      "Epoch 38/75\n",
      " - 19s - loss: 0.4232 - acc: 0.8693 - precision: 0.8818 - recall: 0.8543 - f1_score: 0.8674 - val_loss: 1.7585 - val_acc: 0.4762 - val_precision: 0.4987 - val_recall: 0.4762 - val_f1_score: 0.4872\n",
      "Epoch 39/75\n",
      " - 19s - loss: 0.4214 - acc: 0.8668 - precision: 0.8732 - recall: 0.8643 - f1_score: 0.8686 - val_loss: 1.3558 - val_acc: 0.5238 - val_precision: 0.5238 - val_recall: 0.4762 - val_f1_score: 0.4987\n",
      "Epoch 40/75\n",
      " - 18s - loss: 0.4079 - acc: 0.8819 - precision: 0.8900 - recall: 0.8744 - f1_score: 0.8820 - val_loss: 1.3295 - val_acc: 0.5714 - val_precision: 0.5990 - val_recall: 0.5714 - val_f1_score: 0.5849\n",
      "Epoch 41/75\n",
      " - 18s - loss: 0.3539 - acc: 0.9045 - precision: 0.9044 - recall: 0.8995 - f1_score: 0.9019 - val_loss: 1.5471 - val_acc: 0.5714 - val_precision: 0.5990 - val_recall: 0.5714 - val_f1_score: 0.5849\n",
      "Epoch 42/75\n",
      " - 18s - loss: 0.3850 - acc: 0.8894 - precision: 0.9005 - recall: 0.8894 - f1_score: 0.8948 - val_loss: 1.9224 - val_acc: 0.4762 - val_precision: 0.4709 - val_recall: 0.4286 - val_f1_score: 0.4486\n",
      "Epoch 43/75\n",
      " - 19s - loss: 0.4045 - acc: 0.8794 - precision: 0.8924 - recall: 0.8693 - f1_score: 0.8804 - val_loss: 1.3931 - val_acc: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.5714\n",
      "Epoch 44/75\n",
      " - 20s - loss: 0.4441 - acc: 0.8719 - precision: 0.8849 - recall: 0.8668 - f1_score: 0.8756 - val_loss: 1.4934 - val_acc: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.5238\n",
      "Epoch 45/75\n",
      " - 19s - loss: 0.2823 - acc: 0.9322 - precision: 0.9340 - recall: 0.9246 - f1_score: 0.9292 - val_loss: 1.5226 - val_acc: 0.5238 - val_precision: 0.5489 - val_recall: 0.5238 - val_f1_score: 0.5360\n",
      "Epoch 46/75\n",
      " - 18s - loss: 0.3532 - acc: 0.9045 - precision: 0.9045 - recall: 0.9020 - f1_score: 0.9032 - val_loss: 1.8847 - val_acc: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.5238\n",
      "Epoch 47/75\n",
      " - 20s - loss: 0.4231 - acc: 0.8945 - precision: 0.8965 - recall: 0.8945 - f1_score: 0.8954 - val_loss: 1.5732 - val_acc: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.6190\n",
      "Epoch 48/75\n",
      " - 19s - loss: 0.3580 - acc: 0.8995 - precision: 0.8972 - recall: 0.8920 - f1_score: 0.8945 - val_loss: 1.4884 - val_acc: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.5714\n",
      "Epoch 49/75\n",
      " - 18s - loss: 0.3424 - acc: 0.9045 - precision: 0.9064 - recall: 0.9045 - f1_score: 0.9055 - val_loss: 1.1896 - val_acc: 0.6190 - val_precision: 0.5767 - val_recall: 0.5238 - val_f1_score: 0.5489\n",
      "Epoch 50/75\n",
      " - 19s - loss: 0.2493 - acc: 0.9397 - precision: 0.9397 - recall: 0.9397 - f1_score: 0.9397 - val_loss: 1.5752 - val_acc: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.5714\n",
      "Epoch 51/75\n",
      " - 18s - loss: 0.3085 - acc: 0.9171 - precision: 0.9192 - recall: 0.9171 - f1_score: 0.9181 - val_loss: 1.4882 - val_acc: 0.6190 - val_precision: 0.5990 - val_recall: 0.5714 - val_f1_score: 0.5849\n",
      "Epoch 52/75\n",
      " - 19s - loss: 0.3568 - acc: 0.8995 - precision: 0.9008 - recall: 0.8920 - f1_score: 0.8963 - val_loss: 1.9106 - val_acc: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.5238\n",
      "Epoch 53/75\n",
      " - 18s - loss: 0.3073 - acc: 0.9121 - precision: 0.9167 - recall: 0.9121 - f1_score: 0.9143 - val_loss: 1.5715 - val_acc: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.5714\n",
      "Epoch 54/75\n",
      " - 18s - loss: 0.3919 - acc: 0.8945 - precision: 0.8985 - recall: 0.8920 - f1_score: 0.8952 - val_loss: 1.8000 - val_acc: 0.4762 - val_precision: 0.4762 - val_recall: 0.4762 - val_f1_score: 0.4762\n",
      "Epoch 55/75\n",
      " - 18s - loss: 0.3168 - acc: 0.9121 - precision: 0.9214 - recall: 0.9045 - f1_score: 0.9127 - val_loss: 2.5317 - val_acc: 0.4762 - val_precision: 0.4987 - val_recall: 0.4762 - val_f1_score: 0.4872\n",
      "Epoch 56/75\n",
      " - 18s - loss: 0.3201 - acc: 0.9146 - precision: 0.9187 - recall: 0.9121 - f1_score: 0.9153 - val_loss: 1.7927 - val_acc: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.5714\n",
      "Epoch 57/75\n",
      " - 18s - loss: 0.2309 - acc: 0.9447 - precision: 0.9471 - recall: 0.9447 - f1_score: 0.9459 - val_loss: 1.9517 - val_acc: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.5238\n",
      "Epoch 58/75\n",
      " - 19s - loss: 0.3862 - acc: 0.9070 - precision: 0.9088 - recall: 0.8995 - f1_score: 0.9039 - val_loss: 1.9183 - val_acc: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.6190\n",
      "Epoch 59/75\n",
      " - 18s - loss: 0.3326 - acc: 0.9045 - precision: 0.9100 - recall: 0.8995 - f1_score: 0.9046 - val_loss: 1.1863 - val_acc: 0.5714 - val_precision: 0.6639 - val_recall: 0.5714 - val_f1_score: 0.6139\n",
      "Epoch 60/75\n",
      " - 20s - loss: 0.3021 - acc: 0.9196 - precision: 0.9318 - recall: 0.9020 - f1_score: 0.9161 - val_loss: 1.5136 - val_acc: 0.5714 - val_precision: 0.5990 - val_recall: 0.5714 - val_f1_score: 0.5849\n",
      "Epoch 61/75\n",
      " - 19s - loss: 0.2947 - acc: 0.9322 - precision: 0.9367 - recall: 0.9296 - f1_score: 0.9331 - val_loss: 1.7481 - val_acc: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.5714\n",
      "Epoch 62/75\n",
      " - 18s - loss: 0.2243 - acc: 0.9472 - precision: 0.9490 - recall: 0.9472 - f1_score: 0.9481 - val_loss: 1.5717 - val_acc: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.6190\n",
      "Epoch 63/75\n",
      " - 18s - loss: 0.3993 - acc: 0.8920 - precision: 0.9011 - recall: 0.8744 - f1_score: 0.8867 - val_loss: 2.0037 - val_acc: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.5714\n",
      "Epoch 64/75\n",
      " - 20s - loss: 0.2218 - acc: 0.9447 - precision: 0.9518 - recall: 0.9447 - f1_score: 0.9482 - val_loss: 2.2923 - val_acc: 0.3810 - val_precision: 0.4398 - val_recall: 0.3810 - val_f1_score: 0.4080\n",
      "Epoch 65/75\n",
      " - 18s - loss: 0.2812 - acc: 0.9347 - precision: 0.9364 - recall: 0.9296 - f1_score: 0.9329 - val_loss: 1.7919 - val_acc: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714 - val_f1_score: 0.5714\n",
      "Epoch 66/75\n",
      " - 20s - loss: 0.2816 - acc: 0.9196 - precision: 0.9385 - recall: 0.9045 - f1_score: 0.9186 - val_loss: 1.3193 - val_acc: 0.6190 - val_precision: 0.6825 - val_recall: 0.6190 - val_f1_score: 0.6491\n",
      "Epoch 67/75\n",
      " - 20s - loss: 0.3184 - acc: 0.9246 - precision: 0.9265 - recall: 0.9196 - f1_score: 0.9229 - val_loss: 2.2718 - val_acc: 0.5238 - val_precision: 0.5489 - val_recall: 0.5238 - val_f1_score: 0.5360\n",
      "Epoch 68/75\n",
      " - 19s - loss: 0.2713 - acc: 0.9372 - precision: 0.9460 - recall: 0.9296 - f1_score: 0.9376 - val_loss: 1.8035 - val_acc: 0.5238 - val_precision: 0.5238 - val_recall: 0.3810 - val_f1_score: 0.4398\n",
      "Epoch 69/75\n",
      " - 18s - loss: 0.2576 - acc: 0.9397 - precision: 0.9555 - recall: 0.9196 - f1_score: 0.9366 - val_loss: 1.8609 - val_acc: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.6190\n",
      "Epoch 70/75\n",
      " - 19s - loss: 0.2310 - acc: 0.9447 - precision: 0.9573 - recall: 0.9447 - f1_score: 0.9508 - val_loss: 1.6105 - val_acc: 0.5714 - val_precision: 0.6296 - val_recall: 0.5714 - val_f1_score: 0.5990\n",
      "Epoch 71/75\n",
      " - 18s - loss: 0.3688 - acc: 0.9020 - precision: 0.9127 - recall: 0.8920 - f1_score: 0.9019 - val_loss: 1.4817 - val_acc: 0.6190 - val_precision: 0.6190 - val_recall: 0.6190 - val_f1_score: 0.6190\n",
      "Epoch 72/75\n",
      " - 19s - loss: 0.2726 - acc: 0.9347 - precision: 0.9461 - recall: 0.9271 - f1_score: 0.9361 - val_loss: 1.9436 - val_acc: 0.5238 - val_precision: 0.4987 - val_recall: 0.4762 - val_f1_score: 0.4872\n",
      "Epoch 73/75\n",
      " - 19s - loss: 0.3285 - acc: 0.9271 - precision: 0.9392 - recall: 0.9246 - f1_score: 0.9317 - val_loss: 2.0123 - val_acc: 0.5238 - val_precision: 0.5238 - val_recall: 0.4762 - val_f1_score: 0.4987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/75\n",
      " - 19s - loss: 0.2481 - acc: 0.9472 - precision: 0.9491 - recall: 0.9372 - f1_score: 0.9429 - val_loss: 1.5448 - val_acc: 0.5238 - val_precision: 0.5238 - val_recall: 0.5238 - val_f1_score: 0.5238\n",
      "Epoch 75/75\n",
      " - 21s - loss: 0.2662 - acc: 0.9372 - precision: 0.9463 - recall: 0.9322 - f1_score: 0.9391 - val_loss: 1.3092 - val_acc: 0.5714 - val_precision: 0.6078 - val_recall: 0.5238 - val_f1_score: 0.5624\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.57      0.53         7\n",
      "          1       0.00      0.00      0.00         1\n",
      "          2       0.62      0.67      0.64        12\n",
      "          3       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.52      0.57      0.54        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_22: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9f87952fce39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m    \u001b[1;31m# X_train, X_test = padded_docs[train], padded_docs[test]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;31m#Y_train, Y_test = labels[train], labels[test]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    520\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[0;32m    521\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    472\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    475\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_22: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from keras.preprocessing.text import one_hot\n",
    "#from keras.preprocessing.text import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import History\n",
    "from numpy import zeros\n",
    "from keras.layers.embeddings import Embedding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prf1 import precision, recall, f1_score\n",
    "from keras.utils.vis_utils import plot_model\n",
    "#import pydot\n",
    "#import graphviz\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import LSTM\n",
    "import numpy\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from confusionMetrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from prf1 import precision, recall, f1_score\n",
    "from keras.utils import np_utils\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#######Loading CSV file using Pandas\n",
    " \n",
    "df=pd.read_excel('airtelpcj.xlsx')\n",
    "\n",
    "\n",
    "#print((df.info()))\n",
    "\n",
    "df1=df['message']\n",
    "label =df['Label']\n",
    "\n",
    "#x_val, y_val = sm.fit_sample(x_val1, y_val1)\n",
    "#print(label)\n",
    "#Y=np_utils.to_categorical(Y_old)\n",
    "#print(df1.info())\n",
    "tk=Tokenizer()\n",
    "tk.fit_on_texts(df1)\n",
    "index=tk.word_index\n",
    "#print(index)\n",
    "x = tk.texts_to_sequences(df1)\n",
    "#print (x)\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "##encoded_doc = tk.texts_to_matrix(df, mode='count')\n",
    "##print (encoded_doc)\n",
    "##max_length=15\n",
    "##padded_docs = sequence.pad_sequences(encoded_doc, maxlen=max_length, padding='pre')\n",
    "##print (padded_docs)\n",
    "vocab_size = len(index)\n",
    "\n",
    "\n",
    "#print(vocab_size)\n",
    "encoded_docs=[one_hot(d,vocab_size) for d in df1] \n",
    "#print (hello)\n",
    "##############################Padding###############\n",
    "max_length=50\n",
    "padded_docs = sequence.pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "#print padded_docs\n",
    "#####################Encoded label#######\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(label)\n",
    "encoded_label = encoder.transform(label)\n",
    "#print(encoded_label)\n",
    "labels = np_utils.to_categorical(encoded_label)\n",
    "#print(labels)\n",
    "#print('Shape of data tensor:', x_train.shape)\n",
    "#print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "#x_train1, x_val1, y_train1, y_val1 = check_X_y(padded_docs, labels, accept_sparse=\"csc\", dtype=np.float32, multi_output=True)\n",
    "#x_train1, x_val1, y_train1, y_val1=train_test_split(padded_docs,labels, test_size=0.25,random_state=42)\n",
    "#print(x_train1.shape)\n",
    "#print(x_val1.shape)\n",
    "#print(y_train1.shape)\n",
    "#print(y_val1.shape)\n",
    "#sm = SMOTE(kind='regular')\n",
    "#x_train, y_train = sm.fit_sample(x_train1,y_train1)\n",
    "#x_val,y_val=sm.fit_sample(x_val1,y_val1)\n",
    " \n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt',encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    " \n",
    "print('Total %s word vectors in Glove 6B 100d.' % len(embeddings_index))\n",
    " \n",
    "# In[10]:\n",
    "embedding_matrix =zeros((vocab_size+ 1, 100))\n",
    "for word, i in tk.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector   \n",
    "print (\"Embedding Matrix\")\n",
    " \n",
    " \n",
    " \n",
    "#############embedding layers#########################\n",
    " \n",
    "history=History()\n",
    "predictions_train=[]\n",
    "predictions_test=[]\n",
    "filter_sizes = [3,4,5]\n",
    "fold_training=numpy.zeros(shape=75)\n",
    "fold_test=numpy.zeros(shape=75)\n",
    "##embedding_vecor_length =32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1, 100,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False))\n",
    "##model.add(Embedding(vocab_size,8, input_length=embedding_vecor_length))\n",
    "kfold = KFold(n_splits=20, shuffle=True, random_state=7)\n",
    "cvscores = []\n",
    "ith=1\n",
    "for train,test in kfold.split(padded_docs,labels):\n",
    "    #print('Fold=',ith)\n",
    "    #ith=ith+1\n",
    "    #print(train,test)\n",
    "   # X_train, X_test = padded_docs[train], padded_docs[test]\n",
    "    #Y_train, Y_test = labels[train], labels[test]\n",
    "    model.add(LSTM(100,return_sequences=True))\n",
    "    model.add(LSTM(200,return_sequences=True))\n",
    "    model.add(LSTM(200,return_sequences=True))\n",
    "    model.add(LSTM(200,return_sequences=True,recurrent_dropout=0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='RMSprop',\n",
    "                  metrics=['acc', precision, recall, f1_score])\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', precision,recall,f1_score])\n",
    "    print(model.summary())\n",
    "    history=model.fit(padded_docs[train], labels[train],validation_data=(padded_docs[test],labels[test]),epochs=75, batch_size=20,verbose=2, callbacks=[history])\n",
    "    predictions = model.predict(padded_docs[test])\n",
    "    b=np.zeros_like(predictions)\n",
    "    b[np.arange(len(predictions)), predictions.argmax(1)]=1\n",
    "    print( metrics.classification_report(labels[test],b))\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n",
    "fold_training=numpy.divide(fold_training,20)\n",
    "print(fold_training)\n",
    "fold_test=numpy.divide(fold_test,20)\n",
    "print(fold_test)\n",
    "accuracy = model.evaluate(padded_docs[test],labels[test], verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "    \n",
    "    \n",
    "                               \n",
    "                               \n",
    "    \n",
    "'''history=History()\n",
    "plt.plot(history.history['precision'])\n",
    "plt.plot(history.history['val_precision'])\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
